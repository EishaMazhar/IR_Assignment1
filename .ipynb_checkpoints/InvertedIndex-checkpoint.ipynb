{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking input from stop word list file\n",
    "fObj=open('StopwordList.txt','r')\n",
    "SwContent=fObj.readlines()\n",
    "swlist = [x.replace(\"\\n\",\"\").replace(\" \",\"\") for x in SwContent]\n",
    "swl = [x for x in swlist if x!=\"\"] # stop word list stored in 'swl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(swl)\n",
    "ldict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=glob.glob('Speeches/*')\n",
    "# print(list)\n",
    "for x in list:\n",
    "    f=open(x,'r')\n",
    "    fullfile=f.read().replace(\".\",\"\").replace(\"n't\",\" not\").replace(\"'\",\"\").replace(\"]\",\" \").replace(\"[\",\"\").replace(\",\",\" \").replace(\"?\",\"\").replace(\"\\n\",\" \").replace(\"-\",\" \").split() \n",
    "    lowCasedoc=[porter.stem(x.lower()) for x in fullfile]\n",
    "    withoutstoplist = [x for x in lowCasedoc if x not in swl]\n",
    "#     print(len(withoutstoplist))\n",
    "    p=os.path.basename(x)\n",
    "    p=p.split('.')[0]\n",
    "    ldict[p]=withoutstoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ldict.keys())\n",
    "# temp = 'Speeches\\\\speech_0.txt'\n",
    "# p = os.path.basename(temp)\n",
    "# print(p.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_table={}\n",
    "for key in ldict.keys():\n",
    "    for word in set(ldict[key]):\n",
    "        if word not in index_table:\n",
    "            index_table[word]=[]\n",
    "            index_table[word].append(key)\n",
    "        else:\n",
    "            index_table[word].append(key)\n",
    "            \n",
    "# print(index_table.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in index_table.keys():\n",
    "    unique_elements, counts_elements = np.unique(index_table[x], return_counts=True)\n",
    "    if counts_elements.max() > 1:\n",
    "        print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindex_table={}\n",
    "for key in ldict.keys():\n",
    "    count=0\n",
    "    for word in ldict[key]:\n",
    "        count+=1\n",
    "        if word not in pindex_table:\n",
    "            pindex_table[word]={}\n",
    "            pindex_table[word][key]=[]\n",
    "            pindex_table[word][key].append(count)\n",
    "        else:\n",
    "            if key not in pindex_table[word]:\n",
    "                pindex_table[word][key]=[]\n",
    "            pindex_table[word][key].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pindex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pindex_table.keys()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for key in words:\n",
    "#     print(\"##### new word ######\")\n",
    "#     print(\"key  :  \",key)\n",
    "#     print(pindex_table[key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=input(\"Enter the query \")\n",
    "query=query.replace(\".\",\"\").replace(\"n't\",\" not\").replace(\"]\",\" \").replace(\"[\",\" \").replace(\",\",\" \").replace(\"?\",\"\").replace(\"/\",\" / \").split()\n",
    "stemmedQuery=[porter.stem(x.lower()) for x in query]\n",
    "QueryWithoutStoplist = [x for x in stemmedQuery if x not in swl]\n",
    "print(QueryWithoutStoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for proximity query\n",
    "\n",
    "ProximityValue=0\n",
    "if '/' in stemmedQuery:\n",
    "    ProximityValue = int(QueryWithoutStoplist[QueryWithoutStoplist.index('/')+1])\n",
    "    w1=QueryWithoutStoplist[0]\n",
    "    w2=QueryWithoutStoplist[1]\n",
    "    \n",
    "# elif 'not','and','or' in stemmedQuery:\n",
    "#      print(\"its a boolean query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proximity query function\n",
    "\n",
    "def ProximityQueryProcessing(w1, w2, ProximityValue, pindex_table):\n",
    "    word1={}\n",
    "    word2={}\n",
    "    for word in pindex_table.keys():\n",
    "        if word == w1:\n",
    "            for docid in pindex_table[word]:\n",
    "                word1[docid]=pindex_table[word][docid]\n",
    "        elif word==w2:\n",
    "            for docid in pindex_table[word]:\n",
    "                word2[docid]=pindex_table[word][docid]\n",
    "                \n",
    "    s1=set(word1.keys())\n",
    "    s2=set(word2.keys())\n",
    "    commonDoc=None\n",
    "    commonDoc=s1.intersection(s2)\n",
    "    print(\"s1 : \",s1,\"\\n\\ns2 : \",s2)\n",
    "    print(\"\\n\\n## Common in : \",commonDoc,\"\\n\")\n",
    "    listOfTrueDoc=[]\n",
    "    if commonDoc is not None:\n",
    "        for commonDoc in commonDoc:\n",
    "                x=bool(checkPositions(word1[commonDoc],word2[commonDoc], ProximityValue,commonDoc))\n",
    "                if x==True:\n",
    "                    listOfTrueDoc.append(commonDoc)\n",
    "    else:\n",
    "        print(\"result not found\")\n",
    "        \n",
    "    print(listOfTrueDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPositions(word1, word2, ProximityValue,commonDoc): \n",
    "    for pos1 in word1:\n",
    "        for pos2 in word2:\n",
    "            if (abs(pos1-pos2) - 1) <= ProximityValue:\n",
    "                print(\"DOC--> \",commonDoc,\"-->pos1(\",pos1,\") - pos2(\",pos2,\")\",abs(pos1-pos2)-1)\n",
    "                return True\n",
    "            else:\n",
    "                print(\"false statement : \\n\",\"DOC--> \",commonDoc,\"-->pos1(\",pos1,\") - pos2(\",pos2,\")\",abs(pos1-pos2)-1)\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProximityValue is not 0:\n",
    "    ProximityQueryProcessing(w1,w2,ProximityValue,pindex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if AND, OR, NOT are present then it's boolean (complex boolean query search is compulsory)\n",
    "# phrasal query i.e: 'running after'  (phrasal search is optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
